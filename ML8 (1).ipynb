{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "270cfb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no     0.727273\n",
      "yes    0.272727\n",
      "Name: Buys computer, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data from the image\n",
    "data = {\n",
    "    'Age': [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
    "    'Income': [55000, 48000, 45000, 42000, 37000, 33000, 29000, 25000, 22000, 19000, 16000],\n",
    "    'Student': [0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "    'Credit rating': ['fair', 'good', 'excellent', 'fair', 'fair', 'fair', 'poor', 'poor', 'poor', 'fair', 'poor'],\n",
    "    'Buys computer': ['yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no']\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a Pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Count the number of instances of each class\n",
    "class_counts = df['Buys computer'].value_counts()\n",
    "\n",
    "# Calculate the prior probability for each class\n",
    "prior_probabilities = class_counts / class_counts.sum()\n",
    "\n",
    "# Print the prior probabilities\n",
    "print(prior_probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13c34ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Conditional Densities for Feature: Age\n",
      "\n",
      "Class: yes\n",
      "Density:\n",
      "0    1.510224e-01\n",
      "1    1.627911e-01\n",
      "2    1.689747e-01\n",
      "3    1.627911e-01\n",
      "4    1.510224e-01\n",
      "5    8.213469e-02\n",
      "6    1.804160e-02\n",
      "7    1.477778e-03\n",
      "8    4.461210e-05\n",
      "9    4.955762e-07\n",
      "dtype: float64\n",
      "\n",
      "Class: no\n",
      "Density:\n",
      "0    0.030801\n",
      "1    0.056634\n",
      "2    0.061064\n",
      "3    0.063936\n",
      "4    0.068366\n",
      "5    0.094199\n",
      "6    0.118234\n",
      "7    0.124429\n",
      "8    0.124412\n",
      "9    0.117680\n",
      "dtype: float64\n",
      "\n",
      "Class Conditional Densities for Feature: Income\n",
      "\n",
      "Class: yes\n",
      "Density:\n",
      "0        0.000000e+00\n",
      "1        0.000000e+00\n",
      "2        0.000000e+00\n",
      "3        0.000000e+00\n",
      "4        0.000000e+00\n",
      "             ...     \n",
      "38995    4.955732e-07\n",
      "38996    4.461008e-05\n",
      "38997    1.477283e-03\n",
      "38998    1.799699e-02\n",
      "38999    8.065691e-02\n",
      "Length: 39000, dtype: float64\n",
      "\n",
      "Class: no\n",
      "Density:\n",
      "0        0.049868\n",
      "1        0.030246\n",
      "2        0.006749\n",
      "3        0.000554\n",
      "4        0.000017\n",
      "           ...   \n",
      "38995    0.000000\n",
      "38996    0.000000\n",
      "38997    0.000000\n",
      "38998    0.000000\n",
      "38999    0.000000\n",
      "Length: 39000, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "# Read the data from the image\n",
    "data = {\n",
    "    'Age': [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
    "    'Income': [55000, 48000, 45000, 42000, 37000, 33000, 29000, 25000, 22000, 19000, 16000],\n",
    "    'Student': [0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "    'Credit rating': ['fair', 'good', 'excellent', 'fair', 'fair', 'fair', 'poor', 'poor', 'poor', 'fair', 'poor'],\n",
    "    'Buys computer': ['yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no']\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a Pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate class conditional densities for Age and Income features\n",
    "features = ['Age', 'Income']\n",
    "classes = df['Buys computer'].unique()\n",
    "\n",
    "for feature in features:\n",
    "    print(f\"Class Conditional Densities for Feature: {feature}\\n\")\n",
    "    for class_label in classes:\n",
    "        # Filter data for the specific class label\n",
    "        data_class = df[df['Buys computer'] == class_label][feature]\n",
    "        \n",
    "        # Reshape the data to fit the KDE estimator\n",
    "        data_class = data_class.values.reshape(-1, 1)\n",
    "        \n",
    "        # Fit KDE estimator\n",
    "        kde = KernelDensity(kernel='gaussian').fit(data_class)\n",
    "        \n",
    "        # Generate sample data for which to evaluate the estimated densities\n",
    "        x = pd.DataFrame({feature: range(min(df[feature]), max(df[feature]))})\n",
    "        x_values = x[feature].values.reshape(-1, 1)\n",
    "        \n",
    "        # Evaluate the estimated densities for the sample data\n",
    "        log_density = kde.score_samples(x_values)\n",
    "        density = pd.Series(np.exp(log_density), index=x.index)\n",
    "        \n",
    "        print(f\"Class: {class_label}\\nDensity:\\n{density}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d51a0718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square test result for 'Student' and 'Credit rating':\n",
      "Chi-square value: 2.5732142857142857, p-value: 0.4622047909810518\n",
      "\n",
      "Pearson correlation between 'Age' and 'Income': -0.9965476878818288, p-value: 4.861402895225907e-11\n",
      "Spearman correlation between 'Age' and 'Income': -1.0, p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "# Read the data from the image\n",
    "data = {\n",
    "    'Age': [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
    "    'Income': [55000, 48000, 45000, 42000, 37000, 33000, 29000, 25000, 22000, 19000, 16000],\n",
    "    'Student': [0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "    'Credit rating': ['fair', 'good', 'excellent', 'fair', 'fair', 'fair', 'poor', 'poor', 'poor', 'fair', 'poor'],\n",
    "    'Buys computer': ['yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no']\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a Pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate chi-square test for independence between 'Student' and 'Credit rating'\n",
    "cross_tab = pd.crosstab(df['Student'], df['Credit rating'])\n",
    "chi2, p, _, _ = chi2_contingency(cross_tab)\n",
    "print(f\"Chi-square test result for 'Student' and 'Credit rating':\")\n",
    "print(f\"Chi-square value: {chi2}, p-value: {p}\\n\")\n",
    "\n",
    "# Calculate correlation for 'Age' and 'Income'\n",
    "pearson_corr, pearson_p = pearsonr(df['Age'], df['Income'])\n",
    "spearman_corr, spearman_p = spearmanr(df['Age'], df['Income'])\n",
    "print(f\"Pearson correlation between 'Age' and 'Income': {pearson_corr}, p-value: {pearson_p}\")\n",
    "print(f\"Spearman correlation between 'Age' and 'Income': {spearman_corr}, p-value: {spearman_p}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7912c3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [nan nan 1.  1.  0.5]\n",
      "Mean CV Accuracy: nan\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          no       1.00      0.62      0.77         8\n",
      "         yes       0.50      1.00      0.67         3\n",
      "\n",
      "    accuracy                           0.73        11\n",
      "   macro avg       0.75      0.81      0.72        11\n",
      "weighted avg       0.86      0.73      0.74        11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 507, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 816, in transform\n",
      "    Xs = self._fit_transform(\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 670, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 933, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1016, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 199, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['good'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 507, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 816, in transform\n",
      "    Xs = self._fit_transform(\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 670, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 933, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1016, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 199, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['excellent'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\akshi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Data\n",
    "data = {\n",
    "    'Age': [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
    "    'Income': [55000, 48000, 45000, 42000, 37000, 33000, 29000, 25000, 22000, 19000, 16000],\n",
    "    'Student': [0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "    'Credit rating': ['fair', 'good', 'excellent', 'fair', 'fair', 'fair', 'poor', 'poor', 'poor', 'fair', 'poor'],\n",
    "    'Buys computer': ['yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Features and target variable\n",
    "X = df.drop('Buys computer', axis=1)\n",
    "y = df['Buys computer']\n",
    "\n",
    "# Define columns and transformers for preprocessing\n",
    "categorical_cols = ['Credit rating']\n",
    "categorical_transformer = OneHotEncoder(sparse=False)  # Ensure sparse=False for dense output\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and model\n",
    "pipeline = make_pipeline(preprocessor, GaussianNB())\n",
    "\n",
    "# Perform cross-validation and get accuracy scores\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model on the entire dataset\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Get classification report\n",
    "predictions = pipeline.predict(X)\n",
    "classification_rep = classification_report(y, predictions)\n",
    "\n",
    "# Print results\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72e4d5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       208\n",
      "           1       1.00      1.00      1.00       131\n",
      "\n",
      "    accuracy                           1.00       339\n",
      "   macro avg       1.00      1.00      1.00       339\n",
      "weighted avg       1.00      1.00      1.00       339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_excel('training (2).xlsx')\n",
    "\n",
    "# Assuming 'Classification' is the target variable and you have prepared your features and target as X and y\n",
    "\n",
    "# Separate target variable from features\n",
    "X = data.drop('Classification', axis=1)  # Features\n",
    "y = data['Classification']  # Target variable\n",
    "\n",
    "# Handle categorical variables\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    X[col] = label_encoders[col].fit_transform(X[col])\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')  # You can change the strategy based on your data\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize Gaussian Naive Bayes model\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Train the model\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "classification_rep = classification_report(y_test, predictions)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce03cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
